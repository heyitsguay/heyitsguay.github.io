<!doctype html>
<html lang="">
	<head>
		<title>Scale AI Interview Presentation</title>
		<meta charset="utf-8">
        <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">

        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/theme/white.min.css">
        <link type="text/css" rel="stylesheet" href="index.css">


    </head>

    <body>

    	<div class="reveal">
    		<div class="slides">


    			<section data-background="linear-gradient(#32629780, #65666a0a)">
    				<h3>Scale AI Interview Presentation</h3>
                    <hr/>
                    <br/>
                    May 13, 2020
                    <br/><br/>
    				Matthew Guay
                    <br/>
                    <a href="mailto:matthew.guay@nih.gov" target="_blank">matthew.guay@nih.gov</a>
                    <br/>
                    <a href="mailto:matt.d.guay@gmail.com" target="_blank">matt.d.guay@gmail.com</a>
				
		    <br/><br/>
		    <a href="https://heyitsguay.github.io/scaletalk/" target="_blank">https://heyitsguay.github.io/scaletalk/</a>
    			</section>
		    


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### About me

                        - **Matthew Guay**. Postdoctoral applied computer vision researcher at the NIH.

                        - Background in applied math, scientific computing, image processing, and computer vision.

                        - I love working where computer vision innovation is needed to solve interesting application challenges.
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### About me

                        - **Undergrad**: Cornell 2011, B.A. Mathematics. Undergrad thesis on defining weird PDE solutions on fractals. <a href="https://heyitsguay.github.io/undergradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/undergradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/undergrad.gif" alt="Numerical solutions to fractal equations">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### About me

                        - **Grad school**: UMD 2016, Ph.D. AMSC. Thesis on sparse signal processing in digital and biological systems: <a href="https://heyitsguay.github.io/gradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/gradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/gradsmall.gif" alt="Compressed sensing image reconstruction vs. weighted backprojection">

                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### About me

                        - **Postdoc**: Working with <a href="https://www.nibib.nih.gov/labs-at-nibib/laboratory-cellular-imaging-and-macromolecular-biophysics-lcimb" target="_blank">LCIMB</a> @ NIH on automating segmentation problems for biological electron microscopy.

                        <video width="400" height="400" autoplay muted loop><source src="img/out.mp4" type="video/mp4" /></video>
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Technical challenges
 
                        - Just finished: Scaling a tough 3D semantic segmentation problem. <a href="https://www.biorxiv.org/content/10.1101/2020.01.05.895003v5">[Paper]</a>. <a href="https://leapmanlab.github.io/dense-cell/">[Website]</a>.

                        <img src="img/semantic_overview.png" alt="Large-scale platelet segmentation overview">

                    </textarea>
                </section>
               


               <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Background

                        - Worked with LCIMB in grad school on compressed sensing, but image denoising was not a significant bottleneck.

                        - Bigger problem: **segmentation**. Modern electron microscopes (SBF-SEM, FIB-SEM) rapidly create gigavoxel datasets.

                        - Biologists want structural analysis of <i>everything</i>, but tracing structures by hand is tedious, does not scale.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>

                        <img src="img/platelet-sample2.png" alt="Platelet dataset sample">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Goal

                        - **Automate semantic segmentation** for LCIMB platelet datasets.

                        - LCIMB had manually-labeled images with six classes - cell material and five organelles.

                        - Can a segmentation algorithm produce usable results for scientific research?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Challenges

                        - **3D context**: Necessary for humans. Can I build an algorithm that uses it to do better than 2D segmentation algorithms?

                        - **Architecture design**: When comparing neural net architectures, how to properly decide when one is better?

                        - **Edge preservation**: Biological structures are complicated and densely packed. How to avoid merging together of nearby structures?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - **Establish baselines**. I trained existing 2D U-Net and Deeplab architectures on our segmentation problem, as well as 3D U-Net variants.

                        - Large fully-3D nets require more memory than 2D nets with similar fields of view, causes hardware issues.

                        - Using unpadded convolutions like the original U-Net requires inputs with large z dimension, which is impractical.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Conversations at a conference led to an interest in **hybrid 2D-3D** architectures.

                        - Idea: Use a large memory-friendly 2D module and a smaller 3D module.

                        - Initially saw sequence methods used for 3D, but can also be done with fully-convolutional architectures.

                        - Both modules can be placed in one computation graph and trained end-to-end.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Final architecture: (mostly) 2D U-Net + 3D spatial pooling pyramid.

                        - 2D U-Net has conv block-initial 3x3x3 convs.

                        - 2D module makes intermediate segmentation predictions which are included in the training loss.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/arch.png" alt="Hybrid 2D-3D semantic segmentation architecture">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/loss.png" alt="Training loss equation">

                        Full training loss objective.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - I had to explore new neural net architectures. How do I decide when one is better than another?

                        - Basic: Ablation study for proposed new features.

                        - **Bigger problem**: Initialization-dependent performance.

                        - Random weight initialization induces random distribution of final performance metrics on validation data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - **Solution**: Controlled training of multiple instances per architecture.

                        - Vary only the random seed responsible for weight initialization, create empirical validation performance distributions.

                        - Bonus: When the procedure creates several high-performing instances, they can be ensembled for an overall performance bump.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        <img src="img/performance.png" alt="Validation performance histograms per architecture">

                        Empirical validation MIoU histograms
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Problem**: How to keep, e.g., nearby cells from being merged together by a segmentation algorithm. 

                        - Original U-Net paper uses a weighted loss function that penalizes errors in regions where two cells come close to touching.

                        - Building required knowing which region is cell 1, cell 2, etc.

                        - I wanted to do the same with just voxel-level data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Solution**: Build an error weighting array from three parts.

                        - Weight floor: minimum weight value for each voxel.

                        - Class balancing: Weight each voxel inversely proportionally to its correct class' frequency.

                        - Edge preserving: Use thresholded, scaled diffusion operations to upweight regions where structures almost touch and small cross-sections.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        <img src="img/weights.png" alt="Weight array construction description">

                        Error weight array construction
                        
                    </textarea>
                </section>




                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Results

                        - Final network ensemble tested on multiple datasets including two different physical samples.

                        - Performance compared with human annotators on downstream analysis tasks in addition to standard metrics (MIoU).

                        - Result is nearing human performance, regarded as a viable proof of concept for our institute.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Results

                        <img src="img/volumefraction_small.png" alt="Volume fraction comparison">

                        Organelle volume fraction comparison
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Current and Future Work

                        - Semantic segmentation only one part of a full vision pipeline.

                        - Needs to be combined with instance segmentation.

                        - There is a need for **more robust** segmentation models for multi-dataset annotation.

                        - Predictive tools need to be integrated with human annotation tools.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Current Technical Challenge

                        - Right now: Integrating 3D instance segmentation for panoptic segmentation of cell samples.

                        <img src="img/instance_overview_small.png" alt="3D platelet instance segmentation overview">

                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        **Thank you Scale!!**                        
                    </textarea>
                </section>




    		</div>
    	</div>

        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/marked.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/markdown.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/math/math.js"></script>

        
        <script type="text/javascript">
            Reveal.initialize({

                math: {
                    mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js',
                    config: 'TeX-AMS_HTML-full'
                },

                // Factor of the display size that should remain empty around the content
                margin: 0.03,

                // Display controls in the bottom right corner
                controls: true,

                // Display a presentation progress bar
                progress: true,

                // Set default timing of 2 minutes per slide
                defaultTiming: 90,

                // Display the page number of the current slide
                slideNumber: true,

                // Push each slide change to the browser history
                history: false,

                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Enable the slide overview mode
                overview: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,

                // Change the presentation direction to be RTL
                rtl: false,

                // Randomizes the order of slides each time the presentation loads
                shuffle: false,

                // Turns fragments on and off globally
                fragments: true,

                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Flags if we should show a help overlay when the questionmark
                // key is pressed
                help: true,

                // Flags if speaker notes should be visible to all viewers
                showNotes: false,

                // Global override for autolaying embedded media (video/audio/iframe)
                // - null: Media will only autoplay if data-autoplay is present
                // - true: All media will autoplay, regardless of individual setting
                // - false: No media will autoplay, regardless of individual setting
                autoPlayMedia: null,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Use this method for navigation when auto-sliding
                autoSlideMethod: Reveal.navigateNext,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition style
                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

                // Number of pixels to move the parallax background per slide
                // - Calculated automatically unless specified
                // - Set to 0 to disable movement along an axis
                parallaxBackgroundHorizontal: null,
                parallaxBackgroundVertical: null,

                // The display mode that will be used to show slides
                display: 'block'
            });
        </script>

    </body>
        
</html>
