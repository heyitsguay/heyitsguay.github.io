<!doctype html>
<html lang="">
	<head>
		<title>About Matt Guay</title>
		<meta charset="utf-8">
        <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">

        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/theme/white.min.css">
        <link type="text/css" rel="stylesheet" href="index.css">


    </head>

    <body>

    	<div class="reveal">
    		<div class="slides">


    			<section data-background="linear-gradient(#32629780, #65666a0a)">
    				<h2>About Me</h2>
                    <hr/>
                    <br/>
    				Matthew Guay
                    <br/>
                    <a href="mailto:matt.d.guay@gmail.com" target="_blank">matt.d.guay@gmail.com</a>
                    <br/>
                    <a href="https://www.linkedin.com/in/matthew-guay-51a8451a6/" target="_blank">LinkedIn</a>
                    <br/>
		            <a href="https://heyitsguay.github.io/aboutme/" target="_blank">https://heyitsguay.github.io/me/</a>
    			</section>
		    


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Matt Overview

                        - **Matthew Guay**: Biomedical computer vision expert, executing on the full AI project lifecycle.

                        - Leading data science R&D at <a href="https://www.moichor.com" target="_blank">Moichor</a>.

                        - 7 years experience in biomedical computer vision.

                        - 12 years experience in mathematical image processing for biomedical imaging.
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### My Tech Stack

                        - Ubuntu + the usual **Linux** open-source tools.

                        - **Python** + the usual scientific computing libraries.
                            - **PyTorch** and TensorFlow, prefer PyTorch.
                            - Interop with PostgreSQL via psycopg2.

                        - **AWS** for the ML lifecycle (EC2, S3, SageMaker).
                            - Experience with custom clusters (Biowulf @ NIH).
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Talk Overview

                        - **Education**: My drift from mathematical theory to application.

                        - **Experience**: Growing my expertise in biomedical computer vision.

                        - **Goals**: Deepen my technical mastery, drive greater realizations of AI's potential for biomedical imaging.
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Questions for me?

                        - Want more details on anything?

                        - I can follow linked works for a technical deep dive.

                    </textarea>
                </section>


                <section data-background="linear-gradient(#32629780, #65666a0a)">
                    <h2>Education</h2>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Undergraduate education

                        - Cornell 2011, B.A. Mathematics, _magna cum laude_. Thesis: _Infinity-harmonic functions on SG_. <a href="https://heyitsguay.github.io/undergradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/undergradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/undergrad.gif" alt="Numerical solutions to a fractal PDE">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Graduate education

                        - UMD 2016, Ph.D. AMSC. Thesis on sparse signal processing in digital and biological systems: <a href="https://heyitsguay.github.io/gradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/gradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/gradsmall.gif" alt="Compressed sensing image reconstruction vs. weighted backprojection">
                    </textarea>
                </section>


                <section data-background="linear-gradient(#32629780, #65666a0a)">
                    <h2>Experience</h2>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - Led a new AI research project with <a href="https://www.nibib.nih.gov/labs-at-nibib/laboratory-cellular-imaging-and-macromolecular-biophysics-lcimb" target="_blank">LCIMB</a>.

                        - Latest paper: <a href="https://leapmanlab.github.io/dense-cell/" target="_blank">Dense cellular segmentation for EM using 2D-3D neural network ensembles</a>

                        <img src="img/semantic_overview.png" alt="Semantic segmentation of cells and organelles in a platelet SBF-SEM image volume">
                    </textarea>
                </section>


            <section>
                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - **Research**: Improving 3D semantic segmentation, bio-inspired instance segmentation, large-scale self-supervised pretraining.

                        - **Development**: Integrating algorithmic and manual labeling for rapid structural modeling.

                        - **Organizational**: Co-founded <a href="https://ncihub.org/groups/nihai" target="_blank">NIH.AI</a>, the trans-NIH forum for AI discussion. Co-wrote a successful proposal to fund scientific computing capacity for the NIBIB's <a href="https://www.nibib.nih.gov/labs-at-nibib/advanced-imaging-and-microscopy-aim-resource" target="_blank">AIM Resource</a>.
                    </textarea>
                </section>

                <section id="densecellular" data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Dense Cellular Segmentation

                        - _Dense cellular segmentation for EM using 2D-3D neural network ensembles_, Guay et al., 2021.

                        - Full paper: [Link](https://rdcu.be/ceYzq)

                        - **Main idea**: Hybrid 2D-3D convolutional networks offer superior semantic segmentation performance than 2D-only or 3D-only architectures for platelet SBF-SEM analysis.  
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Background

                        - Worked with LCIMB in grad school on compressed sensing, but image denoising was not a significant bottleneck.

                        - Bigger problem: **segmentation**. Modern electron microscopes (SBF-SEM, FIB-SEM) rapidly create gigavoxel datasets.

                        - Biologists want structural analysis of <i>everything</i>, but tracing structures by hand is tedious, does not scale.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>

                        <img src="img/platelet-sample2.png" alt="Platelet dataset sample">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Goal

                        - **Automate semantic segmentation** for LCIMB platelet datasets.

                        - LCIMB had manually-labeled images with six classes - cell material and five organelles.

                        - Can a segmentation algorithm produce usable results for scientific research?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Challenges

                        - **3D context**: Necessary for humans. Can I build an algorithm that uses it to do better than 2D segmentation algorithms?

                        - **Architecture design**: When comparing neural net architectures, how to properly decide when one is better?

                        - **Edge preservation**: Biological structures are complicated and densely packed. How to avoid merging together of nearby structures?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - **Establish baselines**. I trained existing 2D U-Net and Deeplab architectures on our segmentation problem, as well as 3D U-Net variants.

                        - Large fully-3D nets require more memory than 2D nets with similar fields of view, causes hardware issues.

                        - Using unpadded convolutions like the original U-Net requires inputs with large z dimension, which is impractical.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Conversations at a conference led to an interest in **hybrid 2D-3D** architectures.

                        - Idea: Use a large memory-friendly 2D module and a smaller 3D module.

                        - Initially saw sequence methods used for 3D, but can also be done with fully-convolutional architectures.

                        - Both modules can be placed in one computation graph and trained end-to-end.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Final architecture: (mostly) 2D U-Net + 3D spatial pooling pyramid.

                        - 2D U-Net has conv block-initial 3x3x3 convs.

                        - 2D module makes intermediate segmentation predictions which are included in the training loss.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/arch.png" alt="Hybrid 2D-3D semantic segmentation architecture">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/loss.png" alt="Training loss equation">

                        Full training loss objective.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - I had to explore new neural net architectures. How do I decide when one is better than another?

                        - Basic: Ablation study for proposed new features.

                        - **Bigger problem**: Initialization-dependent performance.

                        - Random weight initialization induces random distribution of final performance metrics on validation data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - **Solution**: Controlled training of multiple instances per architecture.

                        - Vary only the random seed responsible for weight initialization, create empirical validation performance distributions.

                        - Bonus: When the procedure creates several high-performing instances, they can be ensembled for an overall performance bump.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        <img src="img/performance.png" alt="Validation performance histograms per architecture">

                        Empirical validation MIoU histograms
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Problem**: How to keep, e.g., nearby cells from being merged together by a segmentation algorithm. 

                        - Original U-Net paper uses a weighted loss function that penalizes errors in regions where two cells come close to touching.

                        - Building required knowing which region is cell 1, cell 2, etc.

                        - I wanted to do the same with just voxel-level data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Solution**: Build an error weighting array from three parts.

                        - Weight floor: minimum weight value for each voxel.

                        - Class balancing: Weight each voxel inversely proportionally to its correct class' frequency.

                        - Edge preserving: Use thresholded, scaled diffusion operations to upweight regions where structures almost touch and small cross-sections.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        <img src="img/weights.png" alt="Weight array construction description">

                        Error weight array construction
                        
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Results

                        - Final network ensemble tested on multiple datasets including two different physical samples.

                        - Performance compared with human annotators on downstream analysis tasks in addition to standard metrics (MIoU).

                        - Result is nearing human performance, regarded as a viable proof of concept for our institute.
                        
                    </textarea>
                </section>

            </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>

                        <img width="80%" height="50%" data-src="img/covid_demo.png" alt="Blood clot from a COVID-19 patient">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - Example talk 1: <a href="https://leapmanlab.github.io/nihai/jan20/" target="_blank">Content-aware Computation for Optical Microscopy</a>

                        - Example talk 2: <a href="https://heyitsguay.github.io/talks/fars1120/" target="_blank">Putting Deep Learning to Work for EM</a>

                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at Moichor

                        - <a href="https://www.moichor.com" target="_blank">Moichor</a>: AI-powered veterinary diagnostics.

                        - Joined as Principal Computer Vision Scientist in May 2021, after April 2021 seed funding.

                        - I tooks us from 1 to ~15 hematology detection and segmentation models.

                        - Used daily in analyzing samples from 200+ veterinary clinics. 

                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at Moichor

                        - I (re)built Moichor's AI R&D infrastructure.
                            - Python + PyTorch on AWS SageMaker.

                        - I handle our full AI process: 
                            - Project strategy and prioritization.
                            - Data management.
                            - Model implementation, training, validation, selection. 
                            - Model deployment, production monitoring.

                    </textarea>
                </section>


                <section data-background="linear-gradient(#32629780, #65666a0a)">
                    <h2>Goals</h2>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Career goals

                        - **Goal**: Solve computer vision challenges that translate into material impact for important biomedical applications.

                        - Research: Deepen technical mastery, especially in scaling up large transformer models.

                        - Organizational: Lead and own larger, more impactful biomedical AI projects.

                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Career goals - Research

                        - Large-scale self-supervised training of multi-task foundation models for pathology computer vision.

                        - Improving cellular morphology classification/segmentation for subtle feature differentation.

                        - Improving model robustness and generalizability.
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Career goals - Organizational

                        - At a seed-stage startup, I deal with the larger business and science contexts for AI R&D.

                        - Beyond my IC work, I want to grow into leading larger projects.

                        - AI has potential for biomedicine; realizing that potential requires careful direction of resources, selection of data + projects.
                    </textarea>
                </section>


                <section id="theend" data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        **Thank you, Gilead!**                        
                    </textarea>
                </section>



    		</div>
    	</div>

        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/marked.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/markdown.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/math/math.js"></script>

        
        <script type="text/javascript">
            Reveal.initialize({

                math: {
                    mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js',
                    config: 'TeX-AMS_HTML-full'
                },

                // Factor of the display size that should remain empty around the content
                margin: 0.03,

                // Display controls in the bottom right corner
                controls: true,

                // Display a presentation progress bar
                progress: true,

                // Set default timing of 2 minutes per slide
                defaultTiming: 90,

                // Display the page number of the current slide
                slideNumber: true,

                // Push each slide change to the browser history
                history: false,

                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Enable the slide overview mode
                overview: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,

                // Change the presentation direction to be RTL
                rtl: false,

                // Randomizes the order of slides each time the presentation loads
                shuffle: false,

                // Turns fragments on and off globally
                fragments: true,

                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Flags if we should show a help overlay when the questionmark
                // key is pressed
                help: true,

                // Flags if speaker notes should be visible to all viewers
                showNotes: false,

                // Global override for autolaying embedded media (video/audio/iframe)
                // - null: Media will only autoplay if data-autoplay is present
                // - true: All media will autoplay, regardless of individual setting
                // - false: No media will autoplay, regardless of individual setting
                autoPlayMedia: null,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Use this method for navigation when auto-sliding
                autoSlideMethod: Reveal.navigateNext,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition style
                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

                // Number of pixels to move the parallax background per slide
                // - Calculated automatically unless specified
                // - Set to 0 to disable movement along an axis
                parallaxBackgroundHorizontal: null,
                parallaxBackgroundVertical: null,

                // The display mode that will be used to show slides
                display: 'block'
            });
        </script>

    </body>
        
</html>
