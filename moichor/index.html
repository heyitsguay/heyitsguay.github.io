<!doctype html>
<html lang="">
	<head>
		<title>Matt Guay Job + Moichor</title>
		<meta charset="utf-8">
        <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">

        
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/reveal.min.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/css/theme/white.min.css">
        <link type="text/css" rel="stylesheet" href="index.css">


    </head>

    <body>

    	<div class="reveal">
    		<div class="slides">


    			<section data-background="linear-gradient(#32629780, #65666a0a)">
    				<h3>Job Talk - <b>Moichor</b></h3>
                    <hr/>
                    <br/>
    				Matthew Guay
    				<br/>
                    <br/>
                    <a href="mailto:matthew.guay@nih.gov" target="_blank">matthew.guay@nih.gov</a>
                    <br/>
                    <a href="mailto:matt.d.guay@gmail.com" target="_blank">matt.d.guay@gmail.com</a>
		    <br/><br/>
		    <a href="https://heyitsguay.github.io/moichor/" target="_blank">https://heyitsguay.github.io/moichor/</a>
    			</section>
		    


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### About me

                        - **Matthew Guay**. Bioinformatics scientist in applied computer vision at the National Institutes of Health.

                        - Working to improve 3D semantic and instance segmentation of cells: more accurate, more robust, across larger scales, with more detail.

                        - Background in applied math, scientific computing, image processing, and computer vision.
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Undergraduate education

                        - Cornell 2011, B.A. Mathematics, _magna cum laude_. Thesis: _Infinity-harmonic functions on SG_. <a href="https://heyitsguay.github.io/undergradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/undergradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/undergrad.gif" alt="Numerical solutions to a fractal PDE">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Graduate education

                        - UMD 2016, Ph.D. AMSC. Thesis on sparse signal processing in digital and biological systems: <a href="https://heyitsguay.github.io/gradthesis.pdf" target="_blank">[Paper]</a>. <a href="https://heyitsguay.github.io/gradpresentation.pdf" target="_blank">[Presentation]</a>.

                        <img src="img/gradsmall.gif" alt="Compressed sensing image reconstruction vs. weighted backprojection">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - Leading a new, small AI research team with <a href="https://www.nibib.nih.gov/labs-at-nibib/laboratory-cellular-imaging-and-macromolecular-biophysics-lcimb" target="_blank">LCIMB</a>.

                        - Latest paper: <a href="https://leapmanlab.github.io/dense-cell/" target="_blank">Dense cellular segmentation for EM using 2D-3D neural network ensembles</a>

                        <img src="img/semantic_overview.png" alt="Compressed sensing image reconstruction vs. weighted backprojection">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - **Current research**: Better 3D instance segmentation, multi-tissue transfer learning, self-supervised pretraining.

                        - **Current development**: Integrating algorithmic and manual labeling for rapid structural modeling of COVID-19 platelet samples.
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>

                        <img width="80%" height="50%" data-src="img/covid_demo.png" alt="Blood clot from a COVID-19 patient">
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - Co-founded <a href="https://ncihub.org/groups/nihai" target="_blank">NIH.AI</a>, the trans-NIH forum for AI discussion.

                        - Spread knowledge of AI techniques to biologists and best practices to technical specialists.

                        - Consulting with groups at the NIH and UMD on starting new computer vision R&D projects.
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Work at NIH

                        - Example talk 1: <a href="https://leapmanlab.github.io/nihai/jan20/" target="_blank">Content-aware Computation for Optical Microscopy</a>

                        - Example talk 2: <a href="https://heyitsguay.github.io/talks/fars1120/" target="_blank">Putting Deep Learning to Work for EM</a>

                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Career interests

                        - Solving computer vision challenges that translate into material impact for interesting biomedical applications.

                        - The research problems: accuracy, robustness, generalization.

                        - The development problems: Infrastructure for rapid experimentation, model analysis, and deployment.

                        - **Moichor** sounds like a great place to work on these things.

                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Questions for me?

                        - Want more details on anything?

                        - I can follow linked works, or do a technical dive into my latest paper.

                    </textarea>
                </section>


                <section id="densecellular" data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Dense Cellular Segmentation

                        - _Dense cellular segmentation for EM using 2D-3D neural network ensembles_, Guay et al., 2021.

                        - Full paper: [Link](https://rdcu.be/ceYzq)

                        - **Main idea**: Hybrid 2D-3D convolutional networks offer superior semantic segmentation performance than 2D-only or 3D-only architectures for platelet SBF-SEM analysis.  
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Background

                        - Worked with LCIMB in grad school on compressed sensing, but image denoising was not a significant bottleneck.

                        - Bigger problem: **segmentation**. Modern electron microscopes (SBF-SEM, FIB-SEM) rapidly create gigavoxel datasets.

                        - Biologists want structural analysis of <i>everything</i>, but tracing structures by hand is tedious, does not scale.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>

                        <img src="img/platelet-sample2.png" alt="Platelet dataset sample">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Goal

                        - **Automate semantic segmentation** for LCIMB platelet datasets.

                        - LCIMB had manually-labeled images with six classes - cell material and five organelles.

                        - Can a segmentation algorithm produce usable results for scientific research?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Challenges

                        - **3D context**: Necessary for humans. Can I build an algorithm that uses it to do better than 2D segmentation algorithms?

                        - **Architecture design**: When comparing neural net architectures, how to properly decide when one is better?

                        - **Edge preservation**: Biological structures are complicated and densely packed. How to avoid merging together of nearby structures?
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - **Establish baselines**. I trained existing 2D U-Net and Deeplab architectures on our segmentation problem, as well as 3D U-Net variants.

                        - Large fully-3D nets require more memory than 2D nets with similar fields of view, causes hardware issues.

                        - Using unpadded convolutions like the original U-Net requires inputs with large z dimension, which is impractical.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Conversations at a conference led to an interest in **hybrid 2D-3D** architectures.

                        - Idea: Use a large memory-friendly 2D module and a smaller 3D module.

                        - Initially saw sequence methods used for 3D, but can also be done with fully-convolutional architectures.

                        - Both modules can be placed in one computation graph and trained end-to-end.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        - Final architecture: (mostly) 2D U-Net + 3D spatial pooling pyramid.

                        - 2D U-Net has conv block-initial 3x3x3 convs.

                        - 2D module makes intermediate segmentation predictions which are included in the training loss.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/arch.png" alt="Hybrid 2D-3D semantic segmentation architecture">
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - 3D Context

                        <img src="img/loss.png" alt="Training loss equation">

                        Full training loss objective.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - I had to explore new neural net architectures. How do I decide when one is better than another?

                        - Basic: Ablation study for proposed new features.

                        - **Bigger problem**: Initialization-dependent performance.

                        - Random weight initialization induces random distribution of final performance metrics on validation data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        - **Solution**: Controlled training of multiple instances per architecture.

                        - Vary only the random seed responsible for weight initialization, create empirical validation performance distributions.

                        - Bonus: When the procedure creates several high-performing instances, they can be ensembled for an overall performance bump.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Architecture Design

                        <img src="img/performance.png" alt="Validation performance histograms per architecture">

                        Empirical validation MIoU histograms
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Problem**: How to keep, e.g., nearby cells from being merged together by a segmentation algorithm. 

                        - Original U-Net paper uses a weighted loss function that penalizes errors in regions where two cells come close to touching.

                        - Building required knowing which region is cell 1, cell 2, etc.

                        - I wanted to do the same with just voxel-level data.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        - **Solution**: Build an error weighting array from three parts.

                        - Weight floor: minimum weight value for each voxel.

                        - Class balancing: Weight each voxel inversely proportionally to its correct class' frequency.

                        - Edge preserving: Use thresholded, scaled diffusion operations to upweight regions where structures almost touch and small cross-sections.
                        
                    </textarea>
                </section>



                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Solutions - Edge Preservation

                        <img src="img/weights.png" alt="Weight array construction description">

                        Error weight array construction
                        
                    </textarea>
                </section>


                <section data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        ### Results

                        - Final network ensemble tested on multiple datasets including two different physical samples.

                        - Performance compared with human annotators on downstream analysis tasks in addition to standard metrics (MIoU).

                        - Result is nearing human performance, regarded as a viable proof of concept for our institute.
                        
                    </textarea>
                </section>
                

                <section id="theend" data-markdown data-background="linear-gradient(#32629780, #65666a0a)">
                    <textarea data-template>
                        **Thank you Moichor!!**                        
                    </textarea>
                </section>



    		</div>
    	</div>

        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/js/reveal.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/marked.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/markdown/markdown.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/3.6.0/plugin/math/math.js"></script>

        
        <script type="text/javascript">
            Reveal.initialize({

                math: {
                    mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js',
                    config: 'TeX-AMS_HTML-full'
                },

                // Factor of the display size that should remain empty around the content
                margin: 0.03,

                // Display controls in the bottom right corner
                controls: true,

                // Display a presentation progress bar
                progress: true,

                // Set default timing of 2 minutes per slide
                defaultTiming: 90,

                // Display the page number of the current slide
                slideNumber: true,

                // Push each slide change to the browser history
                history: false,

                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Enable the slide overview mode
                overview: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,

                // Change the presentation direction to be RTL
                rtl: false,

                // Randomizes the order of slides each time the presentation loads
                shuffle: false,

                // Turns fragments on and off globally
                fragments: true,

                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Flags if we should show a help overlay when the questionmark
                // key is pressed
                help: true,

                // Flags if speaker notes should be visible to all viewers
                showNotes: false,

                // Global override for autolaying embedded media (video/audio/iframe)
                // - null: Media will only autoplay if data-autoplay is present
                // - true: All media will autoplay, regardless of individual setting
                // - false: No media will autoplay, regardless of individual setting
                autoPlayMedia: null,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Use this method for navigation when auto-sliding
                autoSlideMethod: Reveal.navigateNext,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition style
                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

                // Number of pixels to move the parallax background per slide
                // - Calculated automatically unless specified
                // - Set to 0 to disable movement along an axis
                parallaxBackgroundHorizontal: null,
                parallaxBackgroundVertical: null,

                // The display mode that will be used to show slides
                display: 'block'
            });
        </script>

    </body>
        
</html>
